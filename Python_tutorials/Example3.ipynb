{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style = \"text-align:center\" > UniGe Cosmo Machine Learning 2020/21</h1> \n",
    "<h2 style = \"text-align:center\"> Tutorial 3 </h2> \n",
    "<h3 style = \"text-align:center\"> 16.11.2020 - Michele Mancarella</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "> This tutotial deals with classification problems and compares different algorithms. We will **distringuish stars from QSOs in the SDSS catalogue** using photometric data. \n",
    "\n",
    "> Summary:\n",
    "* Reminder of logistic regression\n",
    "* Decision Trees , Random Forests\n",
    "* Hyperparameter tuning, grid search, pipelines\n",
    "* Custom evaluation metrics\n",
    "* Support Vector Machines\n",
    "* k Nearest Neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/MLworkflow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Goals:\n",
    "* Learn how to apply most widely used ML algotithms with sklearn\n",
    "* More advanced: change evaluation metric, pipelines, hyperparameter tuning\n",
    "\n",
    "\n",
    "> Packages and resources:\n",
    "* This tutorial is based on **scikit-learn**. [**scikit-learn**](https://scikit-learn.org/stable/) is an open source, user-friendly machine learning library. It has an extensive documentation as well as tutorials. Check that out ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns#; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "a4_dims = (11.7, 8.27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\"> Data </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroML.datasets import fetch_sdss_galaxy_colors\n",
    "data = fetch_sdss_galaxy_colors()\n",
    "data = data[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy VS Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = list(data.dtype.fields.keys())\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data , columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['u-g'] = df['u']-df['g']\n",
    "df['g-r'] = df['g']-df['r']\n",
    "df['r-i'] = df['r']-df['i']\n",
    "df['i-z'] = df['i']-df['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['specClass_label'] = pd.get_dummies(df['specClass'],prefix='specClass')['specClass_GALAXY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=a4_dims)\n",
    "ax = sns.pairplot( df,\n",
    "                   vars=['u-g', 'g-r', 'r-i', 'i-z'],\n",
    "                     hue='specClass' #, style=hue\n",
    "                     );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=a4_dims)\n",
    "ax = sns.scatterplot( x='u-g',y='i-z', data=df,\n",
    "                   #vars=['u-g', 'g-r', 'r-i', 'i-z'],\n",
    "                     hue='specClass' #, style=hue\n",
    "                     );\n",
    "\n",
    "ax.set_xlim(-0.5, 2.5);\n",
    "ax.set_ylim(-0.5, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = df[['u', 'g', 'r', 'i', 'z', 'u-g', 'g-r', 'r-i', 'i-z']], df['specClass_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More advanced: use k-fold or multiple train-test split !\n",
    "\n",
    "\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size = 0.25, \\\n",
    "                                                   stratify = y_all )\n",
    "\n",
    "# Note: use stratify to keep proportion of output classes when splitting ! \n",
    "# Super important if you have unmbalanced classes\n",
    "# When doing k-fold cross validation, check Stratified k-fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\"> General setup </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def score_res(clf, test_X, test_y, X, y, myCV=10):\n",
    "    y_pred = clf.predict(test_X)\n",
    "    acc = accuracy_score(y_pred, test_y)\n",
    "    scores = cross_val_score(clf, X, y, cv=myCV)\n",
    "    meanAcc=scores.mean()\n",
    "    print('Accuracy : %s \\n' %acc)\n",
    "    print (classification_report(test_y, y_pred))\n",
    "    print ('Confusion_matrix:')\n",
    "    print (confusion_matrix(test_y, y_pred))\n",
    "    print('\\n k-fold cross validation on full dataset with %s folds: ' %myCV)\n",
    "    print (scores)\n",
    "    print(\"\\n Accuracy: %0.2f (+/- %0.2f)\\n\" % (meanAcc, scores.std() * 2))\n",
    "    #scores1=SKFold(clf,all_X,all_y,myCV)\n",
    " \n",
    "    #y_pred=clf.predict(test_X)\n",
    "    #mae=mean_absolute_error(test_y, y_pred)\n",
    "    #print(\"Mean absolute error: %s\" %mae)\n",
    "    return meanAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, classifier, resolution=0.02, eps=0.1):\n",
    "\n",
    "    if isinstance(X,pd.DataFrame):\n",
    "        X=X.to_numpy()\n",
    "        y=y.to_numpy()\n",
    "\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - eps, X[:, 0].max() + eps\n",
    "    x2_min, x2_max = X[:, 1].min() - eps, X[:, 1].max() + eps\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                     np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    \n",
    "    plt.figure(figsize=a4_dims)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.2)#, cmap=cmap)\n",
    "    #plt.xlim(xx1.min(), xx1.max())\n",
    "    #plt.ylim(xx2.min(), xx2.max())\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        sns.scatterplot(x=X[y == cl, 0], y=X[y == cl, 1])\n",
    "                #alpha=0.8, #c=cmap(idx),\n",
    "                #marker=markers[idx], label=cl)\n",
    "    plt.xlim(-0.5, 2.5);\n",
    "    plt.ylim(-1, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\"> Basic ML w. sklearn -  Logistic Regression </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    " \n",
    " Reminder: basic usage of sklearn\n",
    " \n",
    " > *  Split into train/test set:\n",
    "```python \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)```\n",
    "\n",
    "> * Train your model\n",
    "```python \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)```\n",
    "\n",
    "> * Evaluate\n",
    "```python \n",
    "logreg.score(X_test, y_test)```\n",
    " gives accuracy. For other metrics:\n",
    "```python \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "Slightly better: evaluate with k-fold cross validation. This is what the function score_res() does (with accuracy as a metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test_all, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "y_pred_all = logreg.predict(X_test_all)\n",
    "print(precision_score(y_test_all, y_pred_all))\n",
    "print(recall_score(y_test_all, y_pred_all))\n",
    "print(f1_score(y_test_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thr=dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "y_score = logreg.predict_proba(X_test_all)\n",
    "\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], thr[i] = roc_curve(np.eye(2)[y_test_all][:, i], y_score[:,i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(np.eye(2)[y_test_all].ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[8,10]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,10))\n",
    "labels_dict={0: 'QSO', 1:'Galaxy'}\n",
    "colors=['darkorange', 'darkgreen']\n",
    "\n",
    "lw = 2\n",
    "for i_lab in range(2):\n",
    "\n",
    "    step=steps[i_lab]\n",
    "\n",
    "    ax.plot(fpr[i_lab], tpr[i_lab],color=colors[i_lab],\n",
    "         lw=lw, label=labels_dict[i_lab]+', area = %0.2f' % (roc_auc[i_lab]));\n",
    "    for x, y, txt in zip(fpr[i_lab][::step], tpr[i_lab][::step], thr[i_lab][::step]):\n",
    "        ax.annotate(np.round(txt,2), (x, y), fontsize=12);\n",
    "        ax.plot(fpr[i_lab][::step], tpr[i_lab][::step], 'o', color=colors[i_lab], lw=lw);\n",
    "\n",
    "ax.set_xlim([0.0, 1.0]);\n",
    "ax.set_ylim([0.0, 1.05]);\n",
    "ax.set_xlabel('False Positive Rate',fontsize=18);\n",
    "ax.legend(loc=\"lower right\",fontsize=18);\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "ax.set_ylabel('True Positive Rate',fontsize=18);\n",
    "fig.suptitle('Receiver operating characteristic',fontsize=18) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\">  Decision Trees & feature selection </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    " http://scikit-learn.org/stable/modules/tree.html\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blind application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "DTclf = tree.DecisionTreeClassifier()\n",
    "DTclf=DTclf.fit(X_train_all, y_train_all)\n",
    "\n",
    "acc_dectree=score_res(DTclf, X_test_all, y_test_all, X_all, y_all, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With a decision tree, we can visualise the hierarchical partition of the data using [**Graphviz**](http://www.graphviz.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(DTclf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span style=\"color:#09b038; text-decoration : underline\"> Question :</span><br>  \n",
    "    \n",
    "* Do you understand? If so, can you explain it to me? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Fortunately, Decision Trees are **white boxes**: we can compute and visualise *feature importance* to see what feature have larger impact on the final decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_var_imp( model , X , y ):\n",
    "    imp = pd.DataFrame( \n",
    "        model.feature_importances_  , \n",
    "        columns = [ 'Importance' ] , \n",
    "        index = X.columns \n",
    "    )\n",
    "    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n",
    "    imp[:].plot( kind = 'barh' )\n",
    "    print (model.score( X , y ))\n",
    "    return imp\n",
    "\n",
    "myImp=plot_model_var_imp(DTclf,X_test_all,y_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization #1: use less features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[['u-g', 'i-z']] , df['specClass_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, \\\n",
    "                                                   stratify = y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTclf = tree.DecisionTreeClassifier( )\n",
    "DTclf=DTclf.fit(X_train, y_train)\n",
    "\n",
    "acc_dectree=score_res(DTclf, X_test, y_test, X, y, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(DTclf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test, y_test, DTclf, resolution=0.01, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The above decision regions are the perfect example of **overfitting**. Check : see what the performance on the *training set* is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_res(DTclf, X_train, y_train, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better than on test set: we are indeed overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train, y_train, DTclf, resolution=0.001, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/overfitting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization #2 - Reduce depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTclf = tree.DecisionTreeClassifier(max_depth=1, min_samples_split=40)\n",
    "DTclf=DTclf.fit(X_train, y_train)\n",
    "\n",
    "acc_dectree=score_res(DTclf, X_test, y_test, X, y, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(DTclf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test, y_test, DTclf, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_res(DTclf, X_train, y_train, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\"> Advanced grid search </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> Make the above intuitions automatic, scalable, statistically more robust.\n",
    "* automatic, scalable: with pipelines\n",
    "* more robust: optimisze hyperparameters w. cross validation\n",
    "\n",
    "> Cross-validation in sklearn:\n",
    "\n",
    "* Hyperparameters are specified through a dictionary\n",
    "\n",
    "```python\n",
    "\n",
    "params = {\n",
    "   'C': np.logspace(-5, 5, 50) # 50 values equally spaced in Log between 10**-5 and 10**5\n",
    "    \n",
    "}\n",
    "```\n",
    "* Initialize classifier\n",
    "```python\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "```\n",
    "* Use GridSearchCV\n",
    "```python\n",
    "grid = GridSearchCV(logreg, params, verbose=0, cv=3,\\\n",
    "                    scoring=make_scorer(f1_score))\n",
    "# note: refit=True by default\n",
    "grid.fit(X_train, y_train).score(X_test, y_test)\n",
    "```\n",
    "\n",
    "\n",
    "> Pipeline in sklearn. Pipelines are useful to optimize over multiple hyperparameters\n",
    "* Build the pipeline: List all transformations that we want to apply to our data. For each step, a tuple of 2 objects: (name, acual objet performing operation)\n",
    "\n",
    "```python\n",
    "\n",
    "steps = [\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "```\n",
    "\n",
    "* When passing hyperparameters values, we should now specify which ones to use at each step\n",
    "```python\n",
    "params = {\n",
    "    'pca__n_components': np.arange(1, 51, 5),\n",
    "    'rf__n_estimators': np.arange(5, 55, 5)       \n",
    "}\n",
    "grid = GridSearchCV(pipeline, params, verbose=1)\n",
    "```\n",
    "\n",
    "* Fit\n",
    "\n",
    "```python\n",
    "\n",
    "grid.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "# Note: .fit method fits ALL the methods in steps !\n",
    "```\n",
    "\n",
    "* best params:\n",
    "``` python\n",
    "grid.best_params_\n",
    "```\n",
    "\n",
    "* Flexible! You can also optimize on methods , e.g.:\n",
    "```python\n",
    "params_1 = {\n",
    "  'rf': [LogisticRegression(solver='lbfgs', max_iter=500)],\n",
    "  'rf__C': np.logspace(-5,-5,10)\n",
    "}\n",
    "params_2 = {\n",
    "  'rf': [RandomForestClassifier()],\n",
    "  'rf__n_estimators': np.arange(5,55,5) \n",
    "}\n",
    "grid = GridSearchCV(pipeline, [params_1, params_2], verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "def my_pipeline(my_clf, x_train, x_test , y_train, y_test, scorer, parameters):\n",
    "\n",
    "    pipeline = Pipeline([('clf', my_clf)])\n",
    "\n",
    "    nn = x_train.shape[0]\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,verbose=1, scoring=scorer)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print ('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print ('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    predictions = grid_search.predict(x_test)\n",
    "    print (classification_report(y_test, predictions))\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest + different metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/metrics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision : how many predicted galaxies/QSO are actually galaxies? \n",
    "\n",
    "Recall: how many true galaxies/QSO are correctly identified? \n",
    "\n",
    "f1: harmonic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "parameters_rf = {\n",
    "        'clf__criterion': ('gini', 'entropy'),\n",
    "        'clf__max_depth': (1, 2, 3, 5 ),\n",
    "        'clf__min_samples_leaf':( 5, 10, 20),\n",
    "    'clf__min_samples_split':(5, 10, 20)\n",
    "    }\n",
    "\n",
    "class_RF = my_pipeline(ensemble.RandomForestClassifier(n_jobs=-1, random_state=321),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(f1_score), parameters_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train.to_numpy(), y_train.to_numpy(), class_RF, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change metric - recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_RF_2 = my_pipeline(ensemble.RandomForestClassifier(n_jobs=-1, random_state=321),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(recall_score), parameters_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train, y_train, class_RF_2, resolution=0.02, eps=0.1)\n",
    "# reminder: goal is to correctly classify as many galaxies as possible (orange)\n",
    "# price is to lower significantly the recall on the other class, i.e. the true QSOs that are correcly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change metric - precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_RF_3 = my_pipeline(ensemble.RandomForestClassifier(n_jobs=-1, random_state=321),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(precision_score), parameters_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train, y_train, class_RF_3, resolution=0.02, eps=0.1)\n",
    "# precision= ability of the classifier not to label as positive a sample that is negative\n",
    "# Here I want not to label a quasar as galaxy - push to the right where possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom metric\n",
    "\n",
    "Define a function thath specifies your metric and returns the score. Then pass it to the pipeline using make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred): \n",
    "    ''' Computes geometrical mean of precision and recall '''\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    prec=precision_score(y_true, y_pred)\n",
    "    return np.sqrt(rec*prec)\n",
    "\n",
    "\n",
    "# Actually useful for multi class problems: precision/recall on specific subclass\n",
    "def custom_recall(y_true, y_pred): \n",
    "    ''' Computes recall only on labels 0 '''\n",
    "    rec = recall_score(y_true, y_pred, labels=[0], pos_label=0, average='binary')\n",
    "    return rec #target_accuracy\n",
    "\n",
    "my_scorer = make_scorer(custom_recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_RF_1 = my_pipeline(ensemble.RandomForestClassifier(n_jobs=-1, random_state=321),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       my_scorer, parameters_rf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train, y_train, class_RF_1, resolution=0.02, eps=0.1)\n",
    "# reminder: now, the goal is to correctly classify as many QSO as possible (blue) - pushes boundary to the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear boudaries - example: poor evaluation metric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. SVM\n",
    "# http://scikit-learn.org/stable/modules/svm.html#svm-classification\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "parameters_SVM_1 = {'clf__kernel': ['poly', 'linear'],\n",
    "         'clf__C': [1, 0.1, 0.01],\n",
    "          'clf__gamma': [ 0.01, 0.1, 1],\n",
    "          }\n",
    "\n",
    "SVMbest_1=my_pipeline(svm.SVC( class_weight='balanced'),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(precision_score) , parameters_SVM_1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test.to_numpy(), y_test.to_numpy(), SVMbest_1, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to our metric, this is almost the **perfect** classifier!! (looking for max fraction of quasars correcly identified as quasars)\n",
    "let's use a more balanced metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SVMbest_2=my_pipeline(svm.SVC( class_weight='balanced'),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(f1_score), parameters_SVM_1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test.to_numpy(), y_test.to_numpy(), SVMbest_2, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Linear boudaries\n",
    "\n",
    "To do better I might need to draw more complex boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parameters_SVM = {'clf__kernel': ['rbf'],\n",
    "         'clf__C': [0.01,1, 0.5, 0.1],\n",
    "          'clf__gamma': [  0.01, 0.1,1, 5],\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMbest_3=my_pipeline(svm.SVC( class_weight='balanced'),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(recall_score), parameters_SVM )\n",
    "\n",
    "#acc_svc=score_res(SVMbest, X_test, y_test,X, y 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test.to_numpy(), y_test.to_numpy(), SVMbest_3, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMbest_4=my_pipeline(svm.SVC( class_weight='balanced'),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(precision_score), parameters_SVM )\n",
    "\n",
    "#acc_svc=score_res(SVMbest, X_test, y_test,X, y 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test.to_numpy(), y_test.to_numpy(), SVMbest_4, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_recall_1(y_true, y_pred): \n",
    "    ''' Computes recall only on labels 0 '''\n",
    "    rec = recall_score(y_true, y_pred, pos_label=0, average='binary')\n",
    "    return rec #target_accuracy\n",
    "\n",
    "my_scorer_1 = make_scorer(custom_recall_1)\n",
    "\n",
    "# fraction of galaxies correctly classified as galaxies : (true galaxies correcly classified)/(true galaxies correcly classified + quasars misclassified as galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVMbest_5=my_pipeline(svm.SVC( class_weight='balanced'),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       my_scorer_1, parameters_SVM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train.to_numpy(), y_train.to_numpy(), SVMbest_5, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_precision(y_true, y_pred): \n",
    "    ''' Computes recall only on labels 0 '''\n",
    "    rec = precision_score(y_true, y_pred, pos_label=0, average='binary')\n",
    "    return rec #target_accuracy\n",
    "\n",
    "my_scorer_2 = make_scorer(custom_precision)\n",
    "\n",
    "# Maximise fraction of (correctly classified  galaxies)/(all classified as galaxies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMbest_6 = my_pipeline(svm.SVC(),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       my_scorer_2, parameters_SVM )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train.to_numpy(), y_train.to_numpy(), SVMbest_6, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "parameters_KNN = {'clf__n_neighbors': [1, 5, 10, 20, 100],\n",
    "                  'clf__metric': ['euclidean', 'manhattan', 'chebyshev']\n",
    "          }\n",
    "\n",
    "KNN_best_1=my_pipeline(KNeighborsClassifier(),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       my_scorer , parameters_KNN )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test.to_numpy(), y_test.to_numpy(), KNN_best_1, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_best_2=my_pipeline(KNeighborsClassifier(),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(f1_score) , parameters_KNN )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test.to_numpy(), y_test.to_numpy(), KNN_best_2, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_best_3=my_pipeline(KNeighborsClassifier(),\n",
    "                       X_train, X_test, y_train, y_test,\n",
    "                       make_scorer(precision_score)  , parameters_KNN )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train.to_numpy(), y_train.to_numpy(), KNN_best_3, resolution=0.02, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h2 style = \"text-align:center\"> Summary and take away message </h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "> Cross-validation and hyperparameter tuning: do it!\n",
    "\n",
    "> Metric is crucial and subjective: depends on your goals and what kind of error you want to penalise more\n",
    "\n",
    "> Different algorithms according to the king of boudary (e.g. choice of kernels for nonlinear problems)\n",
    "\n",
    "> sklearn-related: use pipelines + gridsearchCV "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
